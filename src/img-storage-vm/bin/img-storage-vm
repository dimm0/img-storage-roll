#!/opt/rocks/bin/python
#
# @Copyright@
#
#                               Rocks(r)
#                        www.rocksclusters.org
#                        version 5.6 (Emerald Boa)
#                        version 6.1 (Emerald Boa)
#
# Copyright (c) 2000 - 2013 The Regents of the University of California.
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are
# met:
#
# 1. Redistributions of source code must retain the above copyright
# notice, this list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright
# notice unmodified and in its entirety, this list of conditions and the
# following disclaimer in the documentation and/or other materials provided
# with the distribution.
#
# 3. All advertising and press materials, printed or electronic, mentioning
# features or use of this software must display the following acknowledgement:
#
#       "This product includes software developed by the Rocks(r)
#       Cluster Group at the San Diego Supercomputer Center at the
#       University of California, San Diego and its contributors."
#
# 4. Except as permitted for the purposes of acknowledgment in paragraph 3,
# neither the name or logo of this software nor the names of its
# authors may be used to endorse or promote products derived from this
# software without specific prior written permission.  The name of the
# software includes the following terms, and any derivatives thereof:
# "Rocks", "Rocks Clusters", and "Avalanche Installer".  For licensing of
# the associated name, interested parties should contact Technology
# Transfer & Intellectual Property Services, University of California,
# San Diego, 9500 Gilman Drive, Mail Code 0910, La Jolla, CA 92093-0910,
# Ph: (858) 534-5815, FAX: (858) 534-7345, E-MAIL:invent@ucsd.edu
#
# THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS''
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
# THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
# PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS
# BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
# BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
# WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
# OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
# IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#
# @Copyright@
#
from rabbit_client.RabbitMQClient import RabbitMQPublisher, RabbitMQConsumer, RabbitMQLocator, SyncRabbitMQPublisher, RabbitMQCommonClient
import logging

from daemon import runner
import subprocess
import time
import json
import random
import re
import signal
import sys
import traceback

class RabbitClientDaemonVm():

    def __init__(self):
        self.stdin_path = '/dev/null'
        self.stdout_path = '/dev/null'
        self.stderr_path = '/tmp/err'
        self.pidfile_path =  '/var/run/imgstoragedaemon.pid'
        self.pidfile_timeout = 5
        self.function_dict = {'set_zvol':self.set_zvol, 'tear_down':self.tear_down, 'list_dev':self.list_dev }
        self.RABBITMQ_URL = RabbitMQLocator().RABBITMQ_URL
        self.NODE_NAME = RabbitMQLocator().NODE_NAME

    """
    Received set_zvol command from nas
    """
    def set_zvol(self, message, props):
        logger.debug("Setting zvol %s"%message['target'])
        if(self.connect_iscsi(message['target'], props.reply_to)):
                mappings = self.get_blk_dev_list()
                if(message['target'] not in mappings.keys()):
                    pass # TODO send error
                else:
                    self.vmPublisher.messages.put({'message': {'action': 'zvol_attached', 'target':message['target'], 'bdev':mappings[message['target']], 'status':'success'}, 'routing_key': props.reply_to})
                    self.vmPublisher.publish_message()
                    logger.debug('Successfully mapped %s to %s'%(message['target'], mappings[message['target']]))
        else:
            self.vmPublisher.messages.put({'message': {'action': 'zvol_attached', 'target':message['target'], 'status':'error'}, 'routing_key': props.reply_to})
            self.vmPublisher.publish_message()
            logger.error('Error mapping %s'%(message['target']))
 

    def list_dev(self, message, props):
        mappings_map = self.get_blk_dev_list()
        logger.debug("Got mappings %s"%mappings_map)
        mappings_ar = []
        for target in mappings_map.keys():
            mappings_ar.append({'target':target, 'device':mappings_map[target]})
        SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=props.reply_to,
            body = {'action': 'list_dev', 'status': 'success', 'dev_list':mappings_ar},
            correlation_id = props.correlation_id)

    def get_blk_dev_list(self):
        cmd = subprocess.Popen(['iscsiadm', '-m', 'session', '-P3'], stdout=subprocess.PIPE)
        mappings = {}
        cur_target = None
        for line in cmd.stdout:
                if "Target: " in line:
                        cur_target = re.search(r'Target: ([\w\-\.]*)$',line, re.M).group(1)
                if 'Attached scsi disk ' in line:
                        blockdev = re.search( r'Attached scsi disk (\w*)', line, re.M)
                        mappings[cur_target] = blockdev.group(1)
        return mappings

    def connect_iscsi(self, iscsi_target, node_name):
        cmd = subprocess.Popen(['iscsiadm', '--mode', 'discovery', '--type', 'sendtargets', '-p', node_name], stdout=subprocess.PIPE)
        logger.debug("Looking for target in iscsiadm output")
        for line in cmd.stdout:
                if iscsi_target in line: #has the target
                    logger.debug("Found iscsi target in iscsiadm output")
                    return subprocess.call(['iscsiadm', '-m', 'node', '-T', iscsi_target, '-p', node_name, '-l']) == 0
        return False

    def disconnect_iscsi(self, iscsi_target):
        return subprocess.call(['iscsiadm', '-m', 'node', '-T', iscsi_target, '-u']) == 0

    """
    Received zvol tear_down command from nas
    """
    def tear_down(self, message, props):
        logger.debug("Tearing down zvol %s"%message['target'])

        mappings_map = self.get_blk_dev_list()

        if((message['target'] not in mappings_map.keys()) or self.disconnect_iscsi(message['target'])):
            self.vmPublisher.messages.put({'message': {'action': 'zvol_detached', 'target':message['target'], 'status':'success'}, 'routing_key': props.reply_to})
            self.vmPublisher.publish_message()
        else: #TODO !?!?!?!?!?!?!?!?!
            logger.error("error detaching the target %s"%message['target'])
            self.vmPublisher.messages.put({'message': {'action': 'zvol_detached', 'target':message['target'], 'status':'error', 'error':'can_not_detach'}, 'routing_key': props.reply_to})
            self.vmPublisher.publish_message()

    def process_message(self, properties, message):
        logger.debug("Received message %s"%message)
        try:
            self.function_dict[message['action']](message, properties)
        except:
            logger.exception("Unexpected error: %s %s"%(sys.exc_info()[0], sys.exc_info()[1]))
            traceback.print_tb(sys.exc_info()[2])

    def run(self):
        self.vmPublisher = RabbitMQCommonClient(self.RABBITMQ_URL, 'rocks.vm-manage', 'direct', self.NODE_NAME, self.process_message)
        self.vmPublisher.run()

    def stop(self):
        self.vmPublisher.stop()
        logger.info('Consumer and publisher stopping called')


logger = logging.getLogger("DaemonLog")
logger.setLevel(logging.DEBUG)
formatter = logging.Formatter("'%(levelname) -10s %(asctime)s %(name) -30s %(funcName) -35s %(lineno) -5d: %(message)s'")
handler = logging.FileHandler("/var/log/rocks/img-storage-vm.log")
handler.setFormatter(formatter)
logger.addHandler(handler)
logging.getLogger("pika.channel").setLevel(logging.DEBUG)
logging.getLogger("pika.channel").addHandler(handler)
logging.getLogger("pika.connection").setLevel(logging.DEBUG)
logging.getLogger("pika.connection").addHandler(handler)   
logging.getLogger("pika.adapters.base_connection").setLevel(logging.DEBUG)
logging.getLogger("pika.adapters.base_connection").addHandler(handler)
logging.getLogger("rabbit_client.RabbitMQClient").setLevel(logging.DEBUG)
logging.getLogger("rabbit_client.RabbitMQClient").addHandler(handler)
#logging.getLogger("pika.heartbeat").setLevel(logging.DEBUG)
#logging.getLogger("pika.heartbeat").addHandler(handler)
#logging.getLogger("pika.adapters.select_connection").setLevel(logging.DEBUG)
#logging.getLogger("pika.adapters.select_connection").addHandler(handler)   


app = RabbitClientDaemonVm()
daemon_runner = runner.DaemonRunner(app)

#This ensures that the logger file handle does not get closed during daemonization
daemon_runner.daemon_context.files_preserve=[handler.stream]
daemon_runner.daemon_context.signal_map = {signal.SIGTERM: lambda signum, frame: app.stop()}

daemon_runner.do_action()
