#!/opt/rocks/bin/python
#
# @Copyright@
#
#                               Rocks(r)
#                        www.rocksclusters.org
#                        version 5.6 (Emerald Boa)
#                        version 6.1 (Emerald Boa)
#
# Copyright (c) 2000 - 2013 The Regents of the University of California.
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are
# met:
#
# 1. Redistributions of source code must retain the above copyright
# notice, this list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright
# notice unmodified and in its entirety, this list of conditions and the
# following disclaimer in the documentation and/or other materials provided
# with the distribution.
#
# 3. All advertising and press materials, printed or electronic, mentioning
# features or use of this software must display the following acknowledgement:
#
#       "This product includes software developed by the Rocks(r)
#       Cluster Group at the San Diego Supercomputer Center at the
#       University of California, San Diego and its contributors."
#
# 4. Except as permitted for the purposes of acknowledgment in paragraph 3,
# neither the name or logo of this software nor the names of its
# authors may be used to endorse or promote products derived from this
# software without specific prior written permission.  The name of the
# software includes the following terms, and any derivatives thereof:
# "Rocks", "Rocks Clusters", and "Avalanche Installer".  For licensing of
# the associated name, interested parties should contact Technology
# Transfer & Intellectual Property Services, University of California,
# San Diego, 9500 Gilman Drive, Mail Code 0910, La Jolla, CA 92093-0910,
# Ph: (858) 534-5815, FAX: (858) 534-7345, E-MAIL:invent@ucsd.edu
#
# THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS''
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
# THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
# PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS
# BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
# BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
# WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
# OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
# IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#
# @Copyright@
#
from rabbit_client.RabbitMQClient import SyncRabbitMQPublisher, RabbitMQLocator, RabbitMQCommonClient
import logging

from daemon import runner

import subprocess
import traceback

import time
import json

from pysqlite2 import dbapi2 as sqlite3
import sys
import signal
import pika
import socket

ZPOOL = 'tank'

class RabbitClientDaemonNas():
    def __init__(self):
        self.stdin_path = '/dev/null'
        self.stdout_path = '/tmp/out.log'
        self.stderr_path = '/tmp/err.log'
        self.pidfile_path =  '/var/run/imgstoragedaemon.pid'
        self.pidfile_timeout = 5
        self.function_dict = {'set_zvol':self.set_zvol, 'tear_down':self.tear_down, 'zvol_attached':self.zvol_attached, 'zvol_detached': self.zvol_detached, 'list_zvols': self.list_zvols, 'del_zvol': self.del_zvol }
        self.RABBITMQ_URL = RabbitMQLocator().RABBITMQ_URL
        self.NODE_NAME = RabbitMQLocator().NODE_NAME

    def run(self):
        with sqlite3.connect('calls.db') as con:
            cur = con.cursor()
            cur.execute('CREATE TABLE IF NOT EXISTS zvol_calls(zvol TEXT PRIMARY KEY NOT NULL, corr_id TEXT NOT NULL, reply_to TEXT NOT NULL, time INT NOT NULL)')
            cur.execute('CREATE TABLE IF NOT EXISTS zvols(zvol TEXT PRIMARY KEY NOT NULL, iscsi_target TEXT UNIQUE, hosting TEXT)')
            con.commit()

        self.vmPublisher = RabbitMQCommonClient(self.RABBITMQ_URL, 'rocks.vm-manage', 'direct', self.NODE_NAME, self.process_message)
        self.vmPublisher.run()

    """
    Received set_zvol command from frontend, passing to compute node
    """
    def set_zvol(self, message, props):
        hosting = message['hosting']
        zvol_name = message['zvol']
        size = message['size']
        logger.debug("Setting zvol %s"%zvol_name)

        with sqlite3.connect('calls.db') as con:
            cur = con.cursor()
            try :
                self.lockZVol(zvol_name, props.correlation_id, props.reply_to)

                if subprocess.call(['zfs', 'list', '%s/%s'%(ZPOOL, zvol_name)]): #zvol not exists
                    cmd = subprocess.Popen(['zfs', 'create', '-V', '%sgb'%size, '%s/%s'%(ZPOOL, zvol_name)], stdout=subprocess.PIPE, stderr = subprocess.PIPE)
                    out, err = cmd.communicate()
                    logger.debug('Created new zvol %s'%zvol_name)
                    if cmd.returncode:
                        logger.error('Error creating zvol: %s'%err)
                        self.releaseZVol(zvol_name)
                        SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=props.reply_to,
                            body = {'action': 'zvol_attached', 'target':zvol_name, 'status': 'error', 'error':'zvol_creation_error', 'error_description':err},
                            correlation_id = props.correlation_id)
                        return

                cur.execute('SELECT iscsi_target FROM zvols WHERE zvol = ?',[zvol_name])
                row = cur.fetchone()
                if (row != None and row[0] != None): #zvol is mapped
                    self.releaseZVol(zvol_name)
                    SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=props.reply_to,
                        body = {'action': 'zvol_attached', 'target':zvol_name, 'status': 'error', 'error':'zvol_mapped'},
                        correlation_id = props.correlation_id)
                    return
                logger.debug('zvol %s is unmapped according to DB'%zvol_name)

                iscsi_target = ''
                cmd = subprocess.Popen(['tgt-setup-lun', '-n', zvol_name, '-d', '/dev/%s/%s'%(ZPOOL, zvol_name), socket.gethostbyname(hosting)], stdout=subprocess.PIPE)
                for line in cmd.stdout:
                    if "Creating new target" in line:
                        iscsi_target = line['Creating new target (name='.__len__():line.index(',')]
                logger.debug('Mapped %s to iscsi target %s'%(zvol_name, iscsi_target))

                cur.execute('INSERT OR REPLACE INTO zvols VALUES (?,?,?) ',(zvol_name, iscsi_target,hosting))
                con.commit()

                self.vmPublisher.messages.put({'message': {'action': 'set_zvol', 'target':iscsi_target}, 'routing_key': hosting, 'reply_to': self.NODE_NAME})
                self.vmPublisher.publish_message()
                logger.debug("Setting iscsi %s sent"%iscsi_target)
            except sqlite3.IntegrityError, msg:
                logger.error("%s"%msg)
                self.releaseZVol(zvol_name)
                SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=props.reply_to,
                    body = {'action': 'zvol_attached', 'target':zvol_name, 'status': 'error', 'error':'zvol_busy'},
                    correlation_id = props.correlation_id)


    """
    Received zvol tear_down command from frontend, passing to compute node
    """
    def tear_down(self, message, props):
        zvol_name = message['zvol']
        logger.debug("Tearing down zvol %s"%zvol_name)
        with sqlite3.connect('calls.db') as con:
            cur = con.cursor()
            try :
                cur.execute('SELECT hosting, iscsi_target FROM zvols WHERE zvol = ?',[zvol_name])
                row = cur.fetchone()
                if row != None:
                    if(row[1] == None): #zvol is not mapped
                        SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=props.reply_to,
                            body = {'action': 'zvol_detached', 'zvol_name':zvol_name, 'status': 'error', 'error':'zvol_not_attached'},
                            correlation_id = props.correlation_id)
                        return

                    if self.find_iscsi_target_num(row[1]) == None:
                        self.targetDetachSuccess(row[1], zvol_name, props.reply_to, props.correlation_id)
                        SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=props.reply_to,
                            body = {'action': 'zvol_detached', 'zvol_name':zvol_name, 'status': 'error', 'error':'zvol_target_not_exists'},
                            correlation_id = props.correlation_id)
                        return

                    self.lockZVol(zvol_name, props.correlation_id, props.reply_to)
                    self.vmPublisher.messages.put({'message': {'action': 'tear_down', 'target':row[1]}, 'routing_key': row[0], 'reply_to': self.NODE_NAME})
                    self.vmPublisher.publish_message()
                    logger.debug("Tearing down zvol %s sent"%zvol_name)
                else:
                    SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=props.reply_to,
                        body = {'action': 'zvol_detached', 'zvol_name':zvol_name, 'status': 'error', 'error':'zvol_not_found'},
                        correlation_id = props.correlation_id)
                    return
            except sqlite3.IntegrityError, msg:
                logger.error("%s"%msg)
                SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=props.reply_to,
                            body = {'action': 'zvol_detached', 'zvol_name':zvol_name, 'status': 'error', 'error':'zvol_busy'},
                            correlation_id = props.correlation_id)
    """
    Received zvol delete command from frontend
    """
    def del_zvol(self, message, props):
        zvol_name = message['zvol']
        logger.debug("Deleting zvol %s"%zvol_name)
        with sqlite3.connect('calls.db') as con:
            cur = con.cursor()
            try :
                self.lockZVol(zvol_name, props.correlation_id, props.reply_to)
                cur.execute('SELECT hosting, iscsi_target FROM zvols WHERE zvol = ?',[zvol_name])
                row = cur.fetchone()
                if row != None:
                    if(row[1] != None): #zvol is mapped
                        SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=props.reply_to,
                            body = {'action': 'zvol_deleted', 'zvol_name':zvol_name, 'status': 'error', 'error':'zvol_attached'},
                            correlation_id = props.correlation_id)
                        return
                    logger.debug("Invoking zfs destroy %s/%s"%(ZPOOL,zvol_name))
                    if not subprocess.call(['zfs', 'destroy', '%s/%s'%(ZPOOL, zvol_name)]):
                        logger.debug('zfs destroy success %s'%zvol_name)
                        cur.execute('DELETE FROM zvols WHERE zvol = ?',[zvol_name])
                        con.commit()
                        SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=props.reply_to,
                            body = {'action': 'zvol_deleted', 'zvol_name':zvol_name, 'status':'success'},
                            correlation_id = props.correlation_id)
                    else:
                        logger.debug('zvol destroy error %s'%zvol_name)
                        SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=props.reply_to,
                            body = {'action': 'zvol_deleted', 'zvol_name':zvol_name, 'status': 'error', 'error':'zvol_attached'},
                            correlation_id = props.correlation_id)
                else:
                    SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=props.reply_to,
                        body = {'action': 'zvol_deleted', 'zvol_name':zvol_name, 'status': 'error', 'error':'zvol_not_found'},
                        correlation_id = props.correlation_id)
            except sqlite3.IntegrityError, msg:
                logger.error("%s"%msg)
                SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=props.reply_to,
                            body = {'action': 'zvol_deleted', 'zvol_name':zvol_name, 'status': 'error', 'error':'zvol_busy'},
                            correlation_id = props.correlation_id)
            finally:
                self.releaseZVol(zvol_name)



    """
    Received zvol_attached notification from compute node, passing to frontend
    """
    def zvol_attached(self, message, props):
        target = message['target']

        logger.debug("Zvol attached %s"%target)
        with sqlite3.connect('calls.db') as con:
            cur = con.cursor()
            cur.execute('SELECT corr_id, reply_to, zvol_calls.zvol FROM zvol_calls JOIN zvols ON zvol_calls.zvol = zvols.zvol WHERE zvols.iscsi_target = ?',[target])
            row = cur.fetchone()
            if row != None:
                self.releaseZVol(row[2])
                if(message['status'] == 'error'):
                    SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=row[1],
                        body = {'action': 'zvol_attached', 'status':'error'},
                        correlation_id = row[0])
                    return
                else:
                    SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=row[1],
                        body = {'action': 'zvol_attached', 'bdev':message['bdev'], 'status':'success'},
                        correlation_id = row[0])
                    return

    """
    Received zvol_detached notification from compute node, passing to frontend
    """
    def zvol_detached(self, message, props):
        target = message['target']
        logger.debug("Got zvol %s detached message"%(target))

        with sqlite3.connect('calls.db') as con:
            cur = con.cursor()

            # get request destination
            cur.execute('SELECT corr_id, reply_to, zvol_calls.zvol FROM zvol_calls JOIN zvols ON zvol_calls.zvol = zvols.zvol WHERE zvols.iscsi_target = ?',[target])
            row = cur.fetchone()

            if(message['status'] == 'error'):
                logger.error('Got error detaching target from compute')
                self.releaseZVol(row[2])
                logger.debug('%s volume released from lock'%row[2])
                SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=row[1],
                    body = {'action': 'zvol_detached', 'status':'error', 'error':'error_detaching_target'},
                    correlation_id = row[0])
                logger.debug('Sent zvol_detached error back to FE')
                return

 
            tgt_num = self.find_iscsi_target_num(target)
            if subprocess.call(['tgtadm', '--lld', 'iscsi', '--op', 'delete', '--mode', 'target', '--tid', tgt_num]):
                logger.error('Error detaching target %s'%target)
                if row != None:
                    SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=row[1],
                        body = {'action': 'zvol_detached', 'status':'error', 'error':'error_detaching_target'},
                        correlation_id = row[0])
                return
            else:
                self.targetDetachSuccess(target, row[2], row[1], row[0])


    '''
    Function is called to indicate the successful iscsi target detach after getting success from compute or if local target not found
    '''
    def targetDetachSuccess(self, target, zvol, routing_key, correlation_id):
        with sqlite3.connect('calls.db') as con:
            cur = con.cursor()

            # remove iscsi target
            cur.execute('UPDATE zvols SET iscsi_target = NULL where iscsi_target = ?',[target])
            con.commit()

            if zvol != None:
                self.releaseZVol(zvol)
                SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=routing_key,
                    body = {'action': 'zvol_detached', 'status':'success'},
                    correlation_id = correlation_id)


    def find_iscsi_target_num(self, target):
        cmd = subprocess.Popen(['tgtadm', '--op', 'show', '--mode', 'target'], stdout=subprocess.PIPE)
        logger.debug("Looking for target's number in output of tgtadm")
        for line in cmd.stdout:
            if line.startswith('Target '):
                if line.split()[2] == target:
                    tgt_num = line.split()[1]
                    logger.debug("target number is %s"%tgt_num)
                    return tgt_num
        return None

    def list_zvols(self, message, properties):
        with sqlite3.connect('calls.db') as con:
            cur = con.cursor()
            cur.execute('SELECT * from zvols')
            r = [dict((cur.description[i][0], value) for i, value in enumerate(row)) for row in cur.fetchall()]
            SyncRabbitMQPublisher(self.RABBITMQ_URL).publish(routing_key=properties.reply_to,
                body = {'action': 'zvol_list', 'status':'success', 'body': r},
                correlation_id = properties.correlation_id)



    def process_message(self, properties, message):
        logger.debug("Received message %s"%message)
        try:
            self.function_dict[message['action']](message, properties)
        except:
            logger.error("Unexpected error: %s %s"%(sys.exc_info()[0], sys.exc_info()[1]))
            traceback.print_tb(sys.exc_info()[2])

    def stop(self):
        self.vmPublisher.stop()
        logger.info('Consumer and publisher stopping called')

    def lockZVol(self, zvol_name, correlation_id, reply_to):
        with sqlite3.connect('calls.db') as con:
            cur = con.cursor()
            cur.execute('INSERT INTO zvol_calls VALUES (?,?,?,?)',(zvol_name, correlation_id, reply_to, time.time()))
            con.commit()

    def releaseZVol(self, zvol):
        with sqlite3.connect('calls.db') as con:
            cur = con.cursor()
            cur.execute('DELETE FROM zvol_calls WHERE zvol = ?',[zvol])
            con.commit()


logger = logging.getLogger("DaemonLog")
logger.setLevel(logging.DEBUG)
formatter = logging.Formatter("'%(levelname) -10s %(asctime)s %(name) -30s %(funcName) -35s %(lineno) -5d: %(message)s'")
handler = logging.FileHandler("/var/log/rocks/img-storage-nas.log")
handler.setFormatter(formatter)
logger.addHandler(handler)
logging.getLogger("pika.channel").setLevel(logging.DEBUG)
logging.getLogger("pika.channel").addHandler(handler)
logging.getLogger("pika.connection").setLevel(logging.DEBUG)
logging.getLogger("pika.connection").addHandler(handler)
logging.getLogger("pika.adapters.base_connection").setLevel(logging.DEBUG)
logging.getLogger("pika.adapters.base_connection").addHandler(handler)
logging.getLogger("rabbit_client.RabbitMQClient").setLevel(logging.DEBUG)
logging.getLogger("rabbit_client.RabbitMQClient").addHandler(handler)
#logging.getLogger("pika.heartbeat").setLevel(logging.DEBUG)
#logging.getLogger("pika.heartbeat").addHandler(handler)

app = RabbitClientDaemonNas()
daemon_runner = runner.DaemonRunner(app)

#This ensures that the logger file handle does not get closed during daemonization
daemon_runner.daemon_context.files_preserve=[handler.stream]
daemon_runner.daemon_context.signal_map = {signal.SIGTERM: lambda signum, frame: app.stop()}

daemon_runner.do_action()
