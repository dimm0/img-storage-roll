#!/opt/rocks/bin/python
#
# @Copyright@
#
# 				Rocks(r)
# 		         www.rocksclusters.org
# 		         version 5.6 (Emerald Boa)
# 		         version 6.1 (Emerald Boa)
#
# Copyright (c) 2000 - 2013 The Regents of the University of California.
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are
# met:
#
# 1. Redistributions of source code must retain the above copyright
# notice, this list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright
# notice unmodified and in its entirety, this list of conditions and the
# following disclaimer in the documentation and/or other materials provided
# with the distribution.
#
# 3. All advertising and press materials, printed or electronic, mentioning
# features or use of this software must display the following acknowledgement:
#
# 	"This product includes software developed by the Rocks(r)
# 	Cluster Group at the San Diego Supercomputer Center at the
# 	University of California, San Diego and its contributors."
#
# 4. Except as permitted for the purposes of acknowledgment in paragraph 3,
# neither the name or logo of this software nor the names of its
# authors may be used to endorse or promote products derived from this
# software without specific prior written permission.  The name of the
# software includes the following terms, and any derivatives thereof:
# "Rocks", "Rocks Clusters", and "Avalanche Installer".  For licensing of
# the associated name, interested parties should contact Technology
# Transfer & Intellectual Property Services, University of California,
# San Diego, 9500 Gilman Drive, Mail Code 0910, La Jolla, CA 92093-0910,
# Ph: (858) 534-5815, FAX: (858) 534-7345, E-MAIL:invent@ucsd.edu
#
# THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS''
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
# THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
# PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS
# BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
# BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
# WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
# OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
# IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#
# @Copyright@
#
from rabbit_client.RabbitMQClient import RabbitMQPublisher, RabbitMQConsumer, SyncRabbitMQPublisher
import logging

from threading import Thread

from daemon import runner

import subprocess

import time
import json

from pysqlite2 import dbapi2 as sqlite3
import sys

import pika

NODE_NAME = 'zfs-0-0' # this node's name

RABBITMQ_SERVER = 'localhost'

try:
    import rocks.db.helper

    db = rocks.db.helper.DatabaseHelper()
    db.connect()
    RABBITMQ_SERVER = db.getHostAttr(db.getHostname('localhost'), 'Kickstart_PrivateHostname')
    db.close()
except ImportError:
    pass

RABBITMQ_URL = 'amqp://guest:guest@%s:5672/%%2F?connection_attempts=3&heartbeat_interval=3600'%RABBITMQ_SERVER

class RabbitClientDaemonNas():
    def __init__(self):
        self.stdin_path = '/dev/null'
        self.stdout_path = '/dev/tty'
        self.stderr_path = '/dev/tty'
        self.pidfile_path =  '/tmp/rabbitclidaemon.pid'
        self.pidfile_timeout = 5
        self.function_dict = {'set_zvol':self.set_zvol, 'tear_down':self.tear_down, 'zvol_attached':self.zvol_attached, 'zvol_detached': self.zvol_detached }



    def run(self):
 	with sqlite3.connect('calls.db') as con:
	    cur = con.cursor()
	    cur.execute('CREATE TABLE IF NOT EXISTS zvol_calls(zvol TEXT PRIMARY KEY NOT NULL, corr_id TEXT NOT NULL, reply_to TEXT NOT NULL, time INT NOT NULL)')
	    cur.execute('CREATE TABLE IF NOT EXISTS zvols(zvol TEXT PRIMARY KEY NOT NULL, iscsi_target TEXT UNIQUE, hosting TEXT)')
	    con.commit()

        # Connect to localhost:5672 as guest with the password guest and virtual host "/" (%2F)
        self.vmPublisher = RabbitMQPublisher(RABBITMQ_URL, 'rocks.vm-manage', 'direct')
        self.vmConsumer = RabbitMQConsumer(RABBITMQ_URL, 'rocks.vm-manage', 'direct', NODE_NAME, self.process_message)

        t_publish = Thread(target=self.vmPublisher.run)
        t_publish.start()
        logger.debug('started publisher')

        t_consume = Thread(target=self.vmConsumer.run)
        t_consume.start()
        logger.debug('started consumer')

        t_publish.join()
        t_consume.join()

    """
    Received set_zvol command from frontend, passing to compute node
    """
    def set_zvol(self, message, props):
        hosting = message['hosting']
        zvol_name = message['zvol']
        size = message['size']
        logger.debug("Setting zvol %s"%zvol_name)

        with sqlite3.connect('calls.db') as con:
            cur = con.cursor()
            try :
                cur.execute('INSERT INTO zvol_calls VALUES (?,?,?,?)',(zvol_name, props.correlation_id, props.reply_to, time.time()))
                con.commit()

		if subprocess.call(['zfs', 'create', '-V', '10gb', 'tank/%s'%zvol_name]):
			logger.error('Error creating zvol')
			SyncRabbitMQPublisher(RABBITMQ_URL).publish(routing_key=props.reply_to,
			    body = {'action': 'zvol_attached', 'target':zvol_name, 'status': 'error', 'error':'zvol_creation_error'},
			    correlation_id = props.correlation_id)
			return
		
		iscsi_target = ''
		cmd = subprocess.Popen(['tgt-setup-lun', '-n', zvol_name, '-d', '/dev/tank/%s'%zvol_name], stdout=subprocess.PIPE)
		for line in cmd.stdout:
    			if "Creating new target" in line:
        			iscsi_target = line['Creating new target (name='.__len__():line.index(',')]
		
                cur.execute('INSERT OR REPLACE INTO zvols VALUES (?,?,?) ',(zvol_name, iscsi_target,hosting))
		con.commit()
 
                self.vmPublisher.messages.put({'message': {'action': 'set_zvol', 'target':iscsi_target}, 'routing_key': hosting, 'reply_to': NODE_NAME})
                logger.debug("Setting iscsi %s sent"%iscsi_target)
            except sqlite3.IntegrityError, msg:
                logger.error("%s"%msg)
                SyncRabbitMQPublisher(RABBITMQ_URL).publish(routing_key=props.reply_to,
                            body = {'action': 'zvol_attached', 'target':zvol_name, 'status': 'error', 'error':'zvol_busy'},
                            correlation_id = props.correlation_id)


    """
    Received zvol tear_down command from frontend, passing to compute node
    """
    def tear_down(self, message, props):
        zvol_name = message['zvol']
        logger.debug("Tearing down zvol %s"%zvol_name)
        with sqlite3.connect('calls.db') as con:
            cur = con.cursor()
            try :
                cur.execute('SELECT hosting, iscsi_target FROM zvols WHERE zvol = ?',[zvol_name])
                row = cur.fetchone()
                if row != None:
                    cur.execute('INSERT INTO zvol_calls VALUES (?,?,?,?)',(zvol_name, props.correlation_id, props.reply_to, time.time()))
                    con.commit()
                    self.vmPublisher.messages.put({'message': {'action': 'tear_down', 'target':row[1]}, 'routing_key': row[0], 'reply_to': NODE_NAME})
                    logger.debug("Tearing down zvol %s sent"%zvol_name)
                else:
                    SyncRabbitMQPublisher(RABBITMQ_URL).publish(routing_key=props.reply_to,
                                body = {'action': 'zvol_detached', 'zvol_name':zvol_name, 'status': 'error', 'error':'zvol_not_found'},
                                correlation_id = props.correlation_id)
            except sqlite3.IntegrityError, msg:
                logger.error("%s"%msg)
                SyncRabbitMQPublisher(RABBITMQ_URL).publish(routing_key=props.reply_to,
                            body = {'action': 'zvol_detached', 'zvol_name':zvol_name, 'status': 'error', 'error':'zvol_busy'},
                            correlation_id = props.correlation_id)


    """
    Received zvol_attached notification from compute node, passing to frontend
    """
    def zvol_attached(self, message, props):
        target = message['target']
        logger.debug("Zvol attached %s"%target)
        with sqlite3.connect('calls.db') as con:
            cur = con.cursor()
            cur.execute('SELECT corr_id, reply_to, zvol_calls.zvol FROM zvol_calls JOIN zvols ON zvol_calls.zvol = zvols.zvol WHERE zvols.iscsi_target = ?',[target])
            row = cur.fetchone()
            if row != None:
                cur.execute('DELETE FROM zvol_calls WHERE zvol = ?',[row[2]])
                con.commit()
                SyncRabbitMQPublisher(RABBITMQ_URL).publish(routing_key=row[1],
                            body = {'action': 'zvol_attached', 'bdev':message['bdev'], 'status':'success'},
                            correlation_id = row[0])

    """
    Received zvol_detached notification from compute node, passing to frontend
    """
    def zvol_detached(self, message, props):
        target = message['target']
        logger.debug("Zvol detached %s"%(target))

	cmd = subprocess.Popen(['tgtadm', '--op', 'show', '--mode', 'target'], stdout=subprocess.PIPE)
	for line in cmd.stdout:
		if line.startswith('Target '):
			if line.split()[2] == target:
				tgt_num = line.split()[1]
                                if subprocess.call(['tgtadm', '--lld', 'iscsi', '--op', 'delete', '--mode', 'target', '--tid', tgt_num]):
					logger.error('Error detaching target %s'%target)
					# Send error back to fe!!!!
				else:
					with sqlite3.connect('calls.db') as con:
					    cur = con.cursor()

					    # get request destination
					    cur.execute('SELECT corr_id, reply_to, zvol_calls.zvol FROM zvol_calls JOIN zvols ON zvol_calls.zvol = zvols.zvol WHERE zvols.iscsi_target = ?',[target])
				    	    row = cur.fetchone()

					    # remove iscsi target
					    cur.execute('UPDATE zvols SET iscsi_target = NULL where iscsi_target = ?',[target])

					    if row != None:
						cur.execute('DELETE FROM zvol_calls WHERE zvol = ?',[row[2]])
						con.commit()
						SyncRabbitMQPublisher(RABBITMQ_URL).publish(routing_key=row[1],
							    body = {'action': 'zvol_detached', 'status':'success'},
							    correlation_id = row[0])


    def process_message(self, properties, message):
        logger.debug("Received message %s"%message)
        self.function_dict[message['action']](message, properties)




logger = logging.getLogger("DaemonLog")
logger.setLevel(logging.DEBUG)
formatter = logging.Formatter("'%(levelname) -10s %(asctime)s %(name) -30s %(funcName) -35s %(lineno) -5d: %(message)s'")
handler = logging.FileHandler("/var/log/rocks/img-storage-nas.log")
handler.setFormatter(formatter)
logger.addHandler(handler)


app = RabbitClientDaemonNas()
daemon_runner = runner.DaemonRunner(app)

#This ensures that the logger file handle does not get closed during daemonization
daemon_runner.daemon_context.files_preserve=[handler.stream]

daemon_runner.do_action()
